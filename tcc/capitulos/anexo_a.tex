\chapter{ANEXO A -- CÓDIGO FONTE DO CODIFICADOR DO SOFTWARE DE REFERÊNCIA - ALTERAÇÕES REALIZADAS}

Este anexo contém o código fonte das alterações realizadas no codificador do software de referência durante o desenvolvimento do trabalho. Como os fontes dos arquivos modificados são muito extensos apenas as partes mais relevantes se encontram neste anexo.

\section{Alterações realizadas no arquivo lencod/inc/configfile.h}

\begin{lstlisting}


/*!
 ***********************************************************************
 *  \file
 *     configfile.h
 *  \brief
 *     Prototypes for configfile.c and definitions of used structures.
 ***********************************************************************
 */

#include "fmo.h"

#ifndef _CONFIGFILE_H_
#define _CONFIGFILE_H_

#include "config_common.h"

#define DEFAULTCONFIGFILENAME "encoder.cfg"

#define PROFILE_IDC                            88
#define LEVEL_IDC                              21
#define OBJECT_DETECTION_ACTIVATE              1 /* Object detection activated */
#define OBJECT_DETECTION_MIN_WIDTH             30 /* Min width of the object in pixels */
#define OBJECT_DETECTION_MIN_HEIGHT            30 /* Min height of the object in pixels */

/* Hysteresis (in frame numbers) between each object search */
#define OBJECT_DETECTION_SEARCH_HYSTERESIS   30 

/* Hysteresis (in frame numbers) to confirm that the tracked object is still there */
#define OBJECT_DETECTION_TRACKING_HYSTERESIS 60 

InputParameters cfgparams;


#ifdef INCLUDED_BY_CONFIGFILE_C
// Mapping_Map Syntax:
// {NAMEinConfigFile,  &cfgparams.VariableName, Type, InitialValue, LimitType, MinLimit, MaxLimit, CharSize}
// Types : {0:int, 1:text, 2: double}
// LimitType: {0:none, 1:both, 2:minimum, 3: QP based}
// We could separate this based on types to make it more flexible and allow also defaults for text types.
Mapping Map[] = {
    
    /* Outros campos da estrutura */

    /* Adding configuration for Object detection/ tracking */
    {"object_detection_enable",                &cfgparams.object_detection_enable,                0,  OBJECT_DETECTION_ACTIVATE,             1,  0.0,              1.0,     },
    {"object_detection_search_hysteresis",     &cfgparams.object_detection_search_hysteresis,     0,  OBJECT_DETECTION_SEARCH_HYSTERESIS,    0,  0.0,              0.0,     },
    {"object_detection_tracking_hysteresis",   &cfgparams.object_detection_tracking_hysteresis,   0,  OBJECT_DETECTION_TRACKING_HYSTERESIS,  0,  0.0,              0.0,     },
    {"object_detection_min_width",             &cfgparams.object_detection_min_width,             0,  OBJECT_DETECTION_MIN_WIDTH,            0,  0.0,              0.0,     },
    {"object_detection_min_height",            &cfgparams.object_detection_min_height,            0,  OBJECT_DETECTION_MIN_HEIGHT,           0,  0.0,              0.0,     },
    {"object_detection_training_file",         &cfgparams.object_detection_training_file,         1,  0.0,                                   0,  0.0,              0.0,  FILE_NAME_SIZE,},

    {NULL,                       NULL,                                   -1,   0.0,                       0,  0.0,              0.0,                             },
};


#endif

#ifndef INCLUDED_BY_CONFIGFILE_C
extern Mapping Map[];
#endif

extern void Configure            (VideoParameters *p_Vid, InputParameters *p_Inp, int ac, char *av[]);
extern void get_number_of_frames (InputParameters *p_Inp, VideoDataFile *input_file);
extern void read_slice_group_info(VideoParameters *p_Vid, InputParameters *p_Inp);

#endif


\end{lstlisting}


\section{Alterações realizadas no arquivo lencod/inc/global.h}

\begin{lstlisting}

//! VideoParameters
typedef struct video_par
{
  /* Campos que existiam na estrutura */

  /* Adicionado metadata extractor */
  MetadataExtractor * metadata_extractor;

  /* Campos que existiam na estrutura */

} VideoParameters;

\end{lstlisting}


\section{Alterações realizadas no arquivo lencod/src/lencod.c}

\begin{lstlisting}

int main(int argc, char **argv)
{

  alloc_encoder(&p_Enc);

  Configure (p_Enc->p_Vid, p_Enc->p_Inp, argc, argv);

  /* initialize metadata extractor */
  if (p_Enc->p_Inp->object_detection_enable) {
    p_Enc->p_Vid->metadata_extractor = metadata_extractor_new(p_Enc->p_Inp->object_detection_min_width, p_Enc->p_Inp->object_detection_min_height, p_Enc->p_Inp->object_detection_search_hysteresis, p_Enc->p_Inp->object_detection_tracking_hysteresis, p_Enc->p_Inp->object_detection_training_file);

    if (!p_Enc->p_Vid->metadata_extractor) {
      printf("ERROR CREATING METADATA EXTRACTOR !!!!\n");
      return -1;
    }
  }

  // init encoder
  init_encoder(p_Enc->p_Vid, p_Enc->p_Inp);

  // encode sequence
  encode_sequence(p_Enc->p_Vid, p_Enc->p_Inp);

  // terminate sequence
  free_encoder_memory(p_Enc->p_Vid, p_Enc->p_Inp);

  if (p_Enc->p_Inp->object_detection_enable) {
    metadata_extractor_free(p_Enc->p_Vid->metadata_extractor);
  }

  free_params (p_Enc->p_Inp);
  free_encoder(p_Enc);

  return 0;
}


\end{lstlisting}


\section{Alterações realizadas no arquivo lencod/src/image.c}

\begin{lstlisting}

static void get_motion_estimation_information(VideoParameters * p_Vid)
{
  int blk_y, blk_x;
  
  /* Macroblocks have a 16X16 size. Blocks have 4X4, each Macroblock have 16 blocks. 
     Here we are going to iterate trough the 4x4 blocks ME info */
  for (blk_y=0; blk_y  < ceil(p_Vid->height / BLOCK_SIZE); blk_y++)
  {

    for(blk_x = 0 ; blk_x < ceil(p_Vid->width / BLOCK_SIZE); blk_x++) {

      PicMotionParams *mv_info_p = &p_Vid->enc_picture->mv_info[blk_y][blk_x];

      metadata_extractor_add_motion_estimation_info(p_Vid->metadata_extractor,
                                                    blk_x,
                                                    blk_y,
                                                    mv_info_p->mv[LIST_0].mv_x,
                                                    mv_info_p->mv[LIST_0].mv_y);
    }

  }

}

static void code_a_plane(VideoParameters *p_Vid, InputParameters *p_Inp)
{
  unsigned int NumberOfCodedMBs = 0;
  int SliceGroup = 0;
  DistMetric distortion; 

  // The slice_group_change_cycle can be changed here.
  // FmoInit() is called before coding each picture, frame or field
  p_Vid->slice_group_change_cycle=1;
  FmoInit(p_Vid, p_Vid->active_pps, p_Vid->active_sps);
  FmoStartPicture (p_Vid);           //! picture level initialization of FMO

  CalculateQuant4x4Param (p_Vid);
  CalculateOffset4x4Param(p_Vid);

  if(p_Inp->Transform8x8Mode)
  {
    CalculateQuant8x8Param (p_Vid);
    CalculateOffset8x8Param(p_Vid);
  }

  reset_pic_bin_count(p_Vid);
  p_Vid->bytes_in_picture = 0;

  while (NumberOfCodedMBs < p_Vid->PicSizeInMbs)       // loop over slices
  {
    // Encode one SLice Group
    while (!FmoSliceGroupCompletelyCoded (p_Vid, SliceGroup))
    {
      // Encode the current slice
      if (!p_Vid->mb_aff_frame_flag)
        NumberOfCodedMBs += encode_one_slice (p_Vid, SliceGroup, NumberOfCodedMBs);
      else
        NumberOfCodedMBs += encode_one_slice_MBAFF (p_Vid, SliceGroup, NumberOfCodedMBs);

      FmoSetLastMacroblockInSlice (p_Vid, p_Vid->current_mb_nr);
      // Proceed to next slice
      p_Vid->current_slice_nr++;
      p_Vid->p_Stats->bit_slice = 0;
    }
    // Proceed to next SliceGroup
    SliceGroup++;
  }
  FmoEndPicture ();

  if ((p_Inp->SkipDeBlockNonRef == 0) || (p_Vid->nal_reference_idc != 0))
  {
    if(p_Inp->RDPictureDeblocking && !p_Vid->TurnDBOff)
    {
      find_distortion(p_Vid, &p_Vid->imgData);
      distortion.value[0] = p_Vid->p_Dist->metric[SSE].value[0];
      distortion.value[1] = p_Vid->p_Dist->metric[SSE].value[1];
      distortion.value[2] = p_Vid->p_Dist->metric[SSE].value[2];
    }
    else
      distortion.value[0] = distortion.value[1] = distortion.value[2] = 0;

    /* Good place to get ME information - Still missing the mb size and the vectors */

    if (p_Inp->object_detection_enable) {
      get_motion_estimation_information(p_Vid);
    }

    DeblockFrame (p_Vid, p_Vid->enc_picture->imgY, p_Vid->enc_picture->imgUV); //comment out to disable deblocking filter

    if(p_Inp->RDPictureDeblocking && !p_Vid->TurnDBOff)
    {
      find_distortion(p_Vid, &p_Vid->imgData);
      if(distortion.value[0]+distortion.value[1]+distortion.value[2] < 
        p_Vid->p_Dist->metric[SSE].value[0]+
        p_Vid->p_Dist->metric[SSE].value[1]+
        p_Vid->p_Dist->metric[SSE].value[2])
      {
        p_Vid->EvaluateDBOff = 1; 
      }
    }
  }
}


int encode_one_frame (VideoParameters *p_Vid, InputParameters *p_Inp)
{
  int i;
  int nplane;

  //Rate control
  int bits = 0;

  TIME_T start_time;
  TIME_T end_time;
  int64  tmp_time;

  p_Vid->me_time = 0;
  p_Vid->rd_pass = 0;

  if( (p_Inp->separate_colour_plane_flag != 0) )
  {
    for( nplane=0; nplane<MAX_PLANE; nplane++ ){
      p_Vid->enc_frame_picture_JV[nplane] = NULL;
    }
  }

  for (i = 0; i < 6; i++)
    p_Vid->enc_frame_picture[i]  = NULL;

  gettime(&start_time);          // start time in ms

  //Rate control
  p_Vid->write_macroblock = FALSE;
  /*
  //Shankar Regunathan (Oct 2002)
  //Prepare Panscanrect SEI payload
  UpdatePanScanRectInfo (p_SEI);
  //Prepare Arbitrarydata SEI Payload
  UpdateUser_data_unregistered (p_SEI);
  //Prepare Registered data SEI Payload
  UpdateUser_data_registered_itu_t_t35 (p_SEI);
  //Prepare RandomAccess SEI Payload
  UpdateRandomAccess (p_Vid);
  */

  put_buffer_frame (p_Vid);    // sets the pointers to the frame structures
                               // (and not to one of the field structures)
  init_frame (p_Vid, p_Inp);

  if (p_Inp->enable_32_pulldown)
  {
    if ( !read_input_data_32pulldown (p_Vid) )
    {
      return 0;
    }
  }
  else
  {
    if ( !read_input_data (p_Vid) )
    {
      return 0;
    }
  }

  process_image(p_Vid, p_Inp);

  if (p_Inp->object_detection_enable) {
    /* This sounds like a good place to process the raw Y imgData. */
    ExtractedMetadata * metadata = metadata_extractor_extract_object_bounding_box(p_Vid->metadata_extractor,
                                                                                  p_Vid->frame_no,
                                                                                  (unsigned char **) p_Vid->imgData.frm_data[0],
                                                                                  p_Vid->imgData.format.width[0],
                                                                                  p_Vid->imgData.format.height[0]);

    if (metadata) {
      int size                = extracted_metadata_get_serialized_size(metadata);
      char * data             = malloc(size);
      NALU_t * nalu           = NULL;
     
      /* Serialize the metadata */
      extracted_metadata_serialize(metadata, data);
      
      /* Insert the serialized metadata on the bitstream as SEI NALU. */
      nalu = user_data_generate_unregistered_sei_nalu(data, size);
      p_Vid->WriteNALU (p_Vid, nalu);

      FreeNALU (nalu);
      free(data);
      extracted_metadata_free(metadata);
    }
    /* End of metadata extracting */
  }

  pad_borders (p_Inp->output, p_Vid->width, p_Vid->height, p_Vid->width_cr, p_Vid->height_cr, p_Vid->imgData.frm_data);

#if (MVC_EXTENSION_ENABLE)
  if(p_Inp->num_of_views==1 || p_Vid->view_id==0)
  {
    p_Vid->field_pic_ptr = p_Vid->field_pic1;
  }
  else
  {
    p_Vid->field_pic_ptr = p_Vid->field_pic2;
  }
#endif

  


  // Following code should consider optimal coding mode. Currently also does not support
  // multiple slices per frame.
  p_Vid->p_Dist->frame_ctr++;
#if (MVC_EXTENSION_ENABLE)
  if (p_Inp->num_of_views == 2)
  {
    p_Vid->p_Dist->frame_ctr_v[p_Vid->view_id]++;
  }
#endif

  if(p_Vid->type == SP_SLICE)
  {
    if(p_Inp->sp2_frame_indicator)
    { // switching SP frame encoding
      p_Vid->sp2_frame_indicator = TRUE;
      read_SP_coefficients(p_Vid, p_Inp);
    }
  }
  else
  {
    p_Vid->sp2_frame_indicator = FALSE;
  }

  if ( p_Inp->WPMCPrecision )
  {
    wpxInitWPXPasses(p_Vid, p_Inp);
    p_Vid->pWPX->curr_wp_rd_pass = p_Vid->pWPX->wp_rd_passes;
    p_Vid->pWPX->curr_wp_rd_pass->algorithm = WP_REGULAR;
  }

  if (p_Inp->PicInterlace == FIELD_CODING)
    perform_encode_field(p_Vid);
  else
    perform_encode_frame(p_Vid);

  p_Vid->p_Stats->frame_counter++;
  p_Vid->p_Stats->frame_ctr[p_Vid->type]++;

  // Here, p_Vid->structure may be either FRAME or BOTTOM FIELD depending on whether AFF coding is used
  // The picture structure decision changes really only the fld_flag
  write_frame_picture(p_Vid);

#if (MVC_EXTENSION_ENABLE)
  if(p_Inp->num_of_views==2)
  {
    // view_id 1 will follow view_id 0 anchor_pic_flag value
    if((p_Vid->anchor_pic_flag[0]==1) && (p_Vid->view_id&1)==0)
    {
      p_Vid->prev_view_is_anchor = 1;
    }
    else
    {
      p_Vid->prev_view_is_anchor = 0;
    }
  }
#endif

  //Need slice data for deblocking in UpdateDecoders
  if (p_Inp->PicInterlace == FRAME_CODING)
  {
    if ((p_Inp->rdopt == 3) && (p_Inp->de == LLN) && (p_Vid->nal_reference_idc != 0))
    {
      UpdateDecoders (p_Vid, p_Inp, p_Vid->enc_picture);      // simulate packet losses and move decoded image to reference buffers
    }

    if (p_Inp->RestrictRef)
      UpdatePixelMap (p_Vid, p_Inp);
  }

  free_slice_data(p_Vid);

  //Rate control
  if ( p_Inp->RCEnable )
  {
    // we could add here a function pointer!
    bits = (int)( p_Vid->p_Stats->bit_ctr - p_Vid->p_Stats->bit_ctr_n )
      + (int)( p_Vid->p_Stats->bit_ctr_filler_data - p_Vid->p_Stats->bit_ctr_filler_data_n );

    if ( p_Inp->RCUpdateMode <= MAX_RC_MODE )
      p_Vid->rc_update_pict_frame_ptr(p_Vid, p_Inp, p_Vid->p_rc_quad, p_Vid->p_rc_gen, bits);

  }

  compute_distortion(p_Vid, &p_Vid->imgData);

  // redundant pictures: save reconstruction to calculate SNR and replace reference picture
  if(p_Inp->redundant_pic_flag)
  {
    storeRedundantFrame(p_Vid);
  }
  store_coded_picture(p_Vid->p_Dpb);

  p_Vid->AverageFrameQP = isign(p_Vid->SumFrameQP) * ((iabs(p_Vid->SumFrameQP) + (int) (p_Vid->FrameSizeInMbs >> 1))/ (int) p_Vid->FrameSizeInMbs);  

  if ( p_Inp->RCEnable && p_Inp->RCUpdateMode <= MAX_RC_MODE && p_Vid->type != B_SLICE && p_Inp->basicunit < p_Vid->FrameSizeInMbs )
    p_Vid->p_rc_quad->CurrLastQP = p_Vid->AverageFrameQP + p_Vid->p_rc_quad->bitdepth_qp_scale;

#ifdef _LEAKYBUCKET_
  // Store bits used for this frame and increment counter of no. of coded frames
  if (!p_Vid->redundant_coding)
  {
    p_Vid->Bit_Buffer[p_Vid->total_frame_buffer++] = (long) (p_Vid->p_Stats->bit_ctr - p_Vid->p_Stats->bit_ctr_n)
      + (long)( p_Vid->p_Stats->bit_ctr_filler_data - p_Vid->p_Stats->bit_ctr_filler_data_n );
  }
#endif

  // POC200301: Verify that POC coding type 2 is not used if more than one consecutive
  // non-reference frame is requested or if decoding order is different from output order
  if (p_Vid->pic_order_cnt_type == 2)
  {
    if (!p_Vid->nal_reference_idc)
      p_Vid->consecutive_non_reference_pictures++;
    else
      p_Vid->consecutive_non_reference_pictures = 0;

    if (p_Vid->frame_no < p_Vid->prev_frame_no || p_Vid->consecutive_non_reference_pictures>1)
      error("POC type 2 cannot be applied for the coding pattern where the encoding /decoding order of pictures are different from the output order.\n", -1);
    p_Vid->prev_frame_no = p_Vid->frame_no;
  }

  gettime(&end_time);    // end time in ms
  tmp_time  = timediff(&start_time, &end_time);
  p_Vid->tot_time += tmp_time;
  tmp_time  = timenorm(tmp_time);
  p_Vid->me_time   = timenorm(p_Vid->me_time);
  if (p_Vid->p_Stats->bit_ctr_parametersets_n!=0 && p_Inp->Verbose != 3)
    ReportNALNonVLCBits(p_Vid, tmp_time);

#if (MVC_EXTENSION_ENABLE)
  if (p_Vid->curr_frm_idx == 0 && !p_Vid->view_id)
#else
  if (p_Vid->curr_frm_idx == 0)
#endif
    ReportFirstframe(p_Vid, tmp_time);
  else
  {
    bits = update_video_stats(p_Vid);

    switch (p_Vid->type)
    {
    case I_SLICE:
    case SI_SLICE:
      ReportI(p_Vid, tmp_time);
      break;
    case B_SLICE:
      ReportB(p_Vid, tmp_time);
      break;
    case SP_SLICE:
      ReportP(p_Vid, tmp_time);
      break;
    case P_SLICE:
    default:
      ReportP(p_Vid, tmp_time);
    }
  }

  if (p_Inp->Verbose == 0)
  {
    //for (i = 0; i <= (p_Vid->number & 0x0F); i++)
    //printf(".");
    //printf("                              \r");
    printf("Completed Encoding Frame %05d.\r", p_Vid->frame_no);
  }
  // Flush output statistics
  fflush(stdout);

  //Rate control
  if(p_Inp->RCEnable)
    p_Vid->rc_update_picture_ptr( p_Vid, p_Inp, bits );

  // update bit counters
  update_bitcounter_stats(p_Vid);

  update_idr_order_stats(p_Vid);

  return 1;
}

\end{lstlisting}


